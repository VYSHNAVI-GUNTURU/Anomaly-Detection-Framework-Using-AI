{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uzy0JTJAk7Cl"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet python-dotenv google-generativeai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDWzA4yiBc7amljOYTMnp8yxUgwB6YqGN4\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "UTyywX_FnKTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Load API key from .env\n",
        "\n",
        "# Text file path containing system logs\n",
        "TEXT_FILE_PATH = \"/content/logdata.txt\"  # Upload this to Colab\n",
        "\n",
        "# Load text logs from file\n",
        "def read_text_from_file():\n",
        "    with open(TEXT_FILE_PATH, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Updated prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are an AI system log analyzer. Your task is to read log entries and determine if they match known system behavior or indicate an anomaly.\n",
        "\n",
        "Below are the known log labels:\n",
        "- HTTP Status\n",
        "- Critical Error\n",
        "- Security Alert\n",
        "- Error\n",
        "- System Notification\n",
        "- Resource Usage\n",
        "- User Action\n",
        "- Workflow Error\n",
        "- Depreciation Warning\n",
        "\n",
        "Instructions:\n",
        "1. If the log clearly matches one of the above categories, return ONLY the label.\n",
        "2. If the log does NOT match any known behavior and shows unusual or repeated suspicious activity (e.g., multiple failed logins, strange access patterns, or unusual errors), return \"Anomaly Detected\".\n",
        "3. DO NOT guess a label if the pattern is unclear or novel â€” prefer \"Anomaly Detected\" in such cases.\n",
        "4. Respond with only a single line output (either a label or \"Anomaly Detected\").\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Log Entry to Classify:\n",
        "{question}\n",
        "\"\"\",\n",
        "    input_variables=[\"context_text\", \"question\"]\n",
        ")\n",
        "\n",
        "# Function to classify the log using Gemini\n",
        "def query_gemini(context_text, question):\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "    prompt = prompt_template.format(context_text=context_text, question=question)\n",
        "    response = model.generate_content([prompt])\n",
        "    return response.text.strip()\n",
        "\n",
        "# Main program\n",
        "if __name__ == \"__main__\":\n",
        "    context_text = read_text_from_file()\n",
        "    print(\"Enter the log line to classify (or type 'exit' to quit):\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Log Entry: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            break\n",
        "        result = query_gemini(context_text, user_input)\n",
        "        print(\"\\nClassification:\\n\", result, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "u_Yxa2EJl_cx",
        "outputId": "dc619cb1-f20a-48c5-b3d7-2a7aa74e31d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the log line to classify (or type 'exit' to quit):\n",
            "\n",
            "Log Entry: 2025-06-27 07:20:25 failed to login 2025-06-27 07:21:25 failed to login 2025-06-27 07:22:25 failed to login\n",
            "\n",
            "Classification:\n",
            " Anomaly Detected \n",
            "\n",
            "Log Entry: \"timestamp\": \"2025-07-19T14:26:52Z\",     \"server_id\": \"srv-107\",     \"metric\": \"network_in\",     \"value\": 1200.5,     \"threshold\": 800.0,     \"anomaly_type\": \"burst\",     \"severity\": \"high\",     \"detected_by\": \"auto-detector-v3\"\n",
            "\n",
            "Classification:\n",
            " Anomaly Detected \n",
            "\n",
            "Log Entry: 2025-06-27 07:20:25,ModernCRM,\"nova.osapi_compute.wsgi.server [req-b9718cd8-f65e-49cc-8349-6cf7122af137 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 \"\"GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1\"\" status: 200 len: 1893 time: 0.2675118\"\n",
            "\n",
            "Classification:\n",
            " HTTP Status \n",
            "\n",
            "Log Entry: exit\n"
          ]
        }
      ]
    }
  ]
}